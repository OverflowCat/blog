---
title: 2023 å¹´æ¯ä¸ªè½¯ä»¶å¼€å‘è€…éƒ½å¿…é¡»çŸ¥é“çš„å…³äº Unicode çš„åŸºæœ¬çŸ¥è¯†
description: ä»ç„¶ä¸å‡†æ‰¾å€Ÿå£ï¼
photo: "https://tonsky.me/blog/unicode/utf8_trend@2x.png"
date: 2023-10-30 00:15:00
categories:
  - è¯‘æ–‡
  - Tonsky
tags:
  - Unicode
hide_title: true
layout: "@/layouts/Tonsky.astro"
langs:
  en: "https://tonsky.me/blog/unicode/"
  fr: "https://www.outofpluto.com/blog/nikita-prokopov-must-read-article-about-utf-8/"
  ja: "https://news.livedoor.com/article/detail/25110416/"
noscript: true
---

import Plane from "./_plane.astro";
import Loud from "./_loud.astro";
import Code from "./_code.astro";
import Img from "./_img.astro";
import { Icon } from "astro-icon";
import "@/styles/icon.less";
import "@/styles/tonsky-fig-new.less";

# The Absolute Minimum Every Software Developer Must Know About Unicode in 2023 (Still No Excuses!)

# 2023 å¹´æ¯ä¸ªè½¯ä»¶å¼€å‘è€…éƒ½å¿…é¡»çŸ¥é“çš„å…³äº Unicode çš„æœ€åŸºæœ¬çš„çŸ¥è¯†ï¼ˆä»ç„¶ä¸å‡†æ‰¾å€Ÿå£ï¼ï¼‰

Twenty years ago, [Joel Spolsky wrote](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/):

äºŒåå¹´å‰ï¼Œ[Joel Spolsky å†™é“](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/)ï¼š

> There Ainâ€™t No Such Thing As Plain Text.
>
> It does not make sense to have a string without knowing what encoding it uses. You can no longer stick your head in the sand and pretend that â€œplainâ€ text is ASCII.

> æ²¡æœ‰æ‰€è°“çš„çº¯æ–‡æœ¬ã€‚
>
> ä¸çŸ¥é“ç¼–ç çš„å­—ç¬¦ä¸²æ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚ä½ ä¸èƒ½åƒé¸µé¸Ÿä¸€æ ·å†æŠŠå¤´åŸ‹åœ¨æ²™å­é‡Œï¼Œå‡è£…ã€Œçº¯ã€æ–‡æœ¬æ˜¯ ASCIIã€‚

A lot has changed in 20 years. In 2003, the main question was: what encoding is this?

20 å¹´è¿‡å»äº†ï¼Œå¾ˆå¤šäº‹æƒ…éƒ½å˜äº†ã€‚2003 å¹´çš„æ—¶å€™ï¼Œä¸»è¦çš„é—®é¢˜æ˜¯ï¼šæ–‡æœ¬ç”¨çš„æ˜¯ä»€ä¹ˆç¼–ç çš„ï¼Ÿ

In 2023, itâ€™s no longer a question: with a 98% probability, itâ€™s UTF-8. Finally! We can stick our heads in the sand again!

åˆ°äº† 2023 å¹´ï¼Œè¿™ä¸å†æ˜¯ä¸€ä¸ªé—®é¢˜ï¼šæœ‰ 98% çš„æ¦‚ç‡æ˜¯ UTF-8ã€‚ç»ˆäºï¼æˆ‘ä»¬å¯ä»¥å†æ¬¡æŠŠå¤´åŸ‹åœ¨æ²™å­é‡Œäº†ï¼

<Img src="utf8_trend@2x.png" width={1024} height={452} />

The question now becomes: how do we use UTF-8 correctly? Letâ€™s see!

ç°åœ¨çš„é—®é¢˜æ˜¯ï¼šæˆ‘ä»¬å¦‚ä½•æ­£ç¡®åœ°ä½¿ç”¨ UTF-8ï¼Ÿè®©æˆ‘ä»¬æ¥çœ‹çœ‹ï¼

## What is Unicode?

## ä»€ä¹ˆæ˜¯ Unicodeï¼Ÿ

Unicode is a standard that aims to unify all human languages, both past and present, and make them work with computers.

Unicode æ˜¯ä¸€ç§æ—¨åœ¨ç»Ÿä¸€è¿‡å»å’Œç°åœ¨çš„æ‰€æœ‰äººç±»è¯­è¨€ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨è®¡ç®—æœºä¸Šä½¿ç”¨çš„æ ‡å‡†ã€‚

In practice, Unicode is a table that assigns unique numbers to different characters.

åœ¨å®è·µä¸­ï¼ŒUnicode æ˜¯ä¸€ä¸ªå°†ä¸åŒå­—ç¬¦åˆ†é…ç»™å”¯ä¸€ç¼–å·çš„è¡¨æ ¼ã€‚

For example:

ä¾‹å¦‚ï¼š

- The Latin letter `A` is assigned the number `65`.
- æ‹‰ä¸å­—æ¯ `A` è¢«åˆ†é…äº†æ•°å­— `65`ã€‚
- The Arabic Letter Seen `Ø³` is `1587`.
- é˜¿æ‹‰ä¼¯å­—æ¯ Seen `Ø³` æ˜¯ `1587`ã€‚
- The Katakana Letter Tu `ãƒ„` is `12484`
- ç‰‡å‡åå­—æ¯ Tu `ãƒ„` æ˜¯ `12484`
- The Musical Symbol G Clef `ğ„` is `119070`.
- éŸ³ä¹è®°å·ä¸­çš„é«˜éŸ³è°±å·ï¼ˆG è°±å·ï¼‰`ğ„` æ˜¯ `119070`ã€‚
- <code class="emoji">ğŸ’©</code> is `128169`.
- <code class="emoji">ğŸ’©</code> æ˜¯ `128169`ã€‚

Unicode refers to these numbers as _code points_.

Unicode å°†è¿™äº›æ•°å­—ç§°ä¸º*ç ä½*ï¼ˆcode pointsï¼‰ã€‚

Since everybody in the world agrees on which numbers correspond to which characters, and we all agree to use Unicode, we can read each otherâ€™s texts.

ç”±äºä¸–ç•Œä¸Šçš„æ¯ä¸ªäººéƒ½åŒæ„å“ªäº›æ•°å­—å¯¹åº”å“ªäº›å­—ç¬¦ï¼Œå¹¶ä¸”æˆ‘ä»¬éƒ½åŒæ„ä½¿ç”¨ Unicodeï¼Œæˆ‘ä»¬å°±å¯ä»¥é˜…è¯»å½¼æ­¤çš„æ–‡æœ¬ã€‚

<Loud en="Unicode == character âŸ· code point.">Unicode == å­—ç¬¦ âŸ· ç ä½ã€‚</Loud>

## How big is Unicode?

## Unicode æœ‰å¤šå¤§ï¼Ÿ

Currently, the largest defined code point is 0x10FFFF. That gives us a space of about 1.1 million code points.

ç›®å‰ï¼Œå·²è¢«å®šä¹‰çš„æœ€å¤§ç ä½æ˜¯ 0x10FFFFã€‚è¿™ç»™äº†æˆ‘ä»¬å¤§çº¦ 110 ä¸‡ä¸ªç ä½çš„ç©ºé—´ã€‚

About 170,000, or 15%, are currently defined. An additional 11% are reserved for private use. The rest, about 800,000 code points, are not allocated at the moment. They could become characters in the future.

ç›®å‰å·²å®šä¹‰äº†å¤§çº¦ 17 ä¸‡ä¸ªç ä½ï¼Œå  15%ã€‚å¦å¤– 11% ç”¨äºç§æœ‰ä½¿ç”¨ã€‚å…¶ä½™çš„å¤§çº¦ 80 ä¸‡ä¸ªç ä½ç›®å‰æ²¡æœ‰åˆ†é…ã€‚å®ƒä»¬å¯èƒ½åœ¨æœªæ¥å˜æˆå­—ç¬¦ã€‚

Hereâ€™s roughly how it looks:

è¿™é‡Œæ˜¯å¤§è‡´çš„æ ·å­ï¼š

<Img src="https://tonsky.me/blog/unicode/overview@2x.png" width={835} height={735} />

Large square == plane == 65,536 characters. Small one == 256 characters. The entire ASCII is half of a small red square in the top left corner.

å¤§æ–¹æ¡† == å¹³é¢ == 65,536 ä¸ªå­—ç¬¦ã€‚å°æ–¹æ¡† == 256 ä¸ªå­—ç¬¦ã€‚æ•´ä¸ª ASCII æ˜¯å·¦ä¸Šè§’å°çº¢è‰²æ–¹å—çš„ä¸€åŠã€‚

## Whatâ€™s Private Use?

## ä»€ä¹ˆæ˜¯ç§ç”¨åŒºï¼Ÿ

These are code points reserved for app developers and will never be defined by Unicode itself.

è¿™äº›ç ä½æ˜¯ä¸ºåº”ç”¨ç¨‹åºå¼€å‘äººå‘˜ä¿ç•™çš„ï¼ŒUnicode è‡ªå·±æ°¸è¿œä¸ä¼šå®šä¹‰å®ƒä»¬ã€‚

For example, thereâ€™s no place for the Apple logo in Unicode, so Apple puts it at `U+F8FF` which is within the Private Use block. In any other font, itâ€™ll render as missing glyph `ô€£º`, but in fonts that ship with macOS, youâ€™ll see <Icon name="ic:baseline-apple" height="17px" />.

ä¾‹å¦‚ï¼ŒUnicode ä¸­æ²¡æœ‰è‹¹æœ logo çš„ä½ç½®ï¼Œå› æ­¤ Apple å°†å…¶æ”¾åœ¨ç§ç”¨åŒºå—ä¸­çš„ `U+F8FF`ã€‚åœ¨ä»»ä½•å…¶ä»–å­—ä½“ä¸­ï¼Œå®ƒéƒ½å°†å‘ˆç°ä¸ºç¼ºå¤±çš„å­—å½¢ `ô€£º`ï¼Œä½†åœ¨ macOS é™„å¸¦çš„å­—ä½“ä¸­ï¼Œä½ å°±å¯ä»¥çœ‹åˆ° <Icon name="ic:baseline-apple" height="17px" />ã€‚

The Private Use Area is mostly used by icon fonts:

ç§ç”¨åŒºä¸»è¦ç”±å›¾æ ‡å­—ä½“ä½¿ç”¨ï¼š

<Img src="https://tonsky.me/blog/unicode/nerd_font@2x.png"
  width="584"
  height="268"
  encap="Isnâ€™t it a beauty? Itâ€™s all text!"
  zhcap="æ˜¯ä¸æ˜¯å¾ˆæ¼‚äº®ï¼Ÿéƒ½æ˜¯æ–‡æœ¬å“¦ï¼"
/>

## What does `U+1F4A9` mean?

## `U+1F4A9` æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ

Itâ€™s a convention for how to write code point values. The prefix `U+` means, well, Unicode, and `1F4A9` is a code point number in hexadecimal.

è¿™æ˜¯ä¸€ç§ç ä½å€¼å†™æ³•çš„çº¦å®šã€‚å‰ç¼€ `U+` è¡¨ç¤º Unicodeï¼Œ`1F4A9` æ˜¯åå…­è¿›åˆ¶ä¸­çš„ç ä½æ•°å­—ã€‚

Oh, and `U+1F4A9` specifically is <code class="emoji">ğŸ’©</code>.

å™¢ï¼Œ`U+1F4A9` å…·ä½“æ˜¯ <code class="emoji">ğŸ’©</code>ã€‚

## Whatâ€™s UTF-8 then?

## é‚£ UTF-8 æ˜¯ä»€ä¹ˆï¼Ÿ

UTF-8 is an encoding. Encoding is how we store code points in memory.

UTF-8 æ˜¯ä¸€ç§ç¼–ç ã€‚ç¼–ç æ˜¯æˆ‘ä»¬åœ¨å†…å­˜ä¸­å­˜å‚¨ç ä½çš„æ–¹å¼ã€‚

The simplest possible encoding for Unicode is UTF-32. It simply stores code points as 32-bit integers. So `U+1F4A9` becomes `00 01 F4 A9`, taking up four bytes. Any other code point in UTF-32 will also occupy four bytes. Since the highest defined code point is `U+10FFFF`, any code point is guaranteed to fit.

Unicode æœ€ç®€å•çš„ç¼–ç æ˜¯ UTF-32ã€‚å®ƒåªæ˜¯å°†ç ä½å­˜å‚¨ä¸º 32 ä½æ•´æ•°ã€‚å› æ­¤ï¼Œ`U+1F4A9` å˜ä¸º `00 01 F4 A9`ï¼Œå ç”¨å››ä¸ªå­—èŠ‚ã€‚UTF-32 ä¸­çš„ä»»ä½•å…¶ä»–ç ä½ä¹Ÿå°†å ç”¨å››ä¸ªå­—èŠ‚ã€‚ç”±äºæœ€é«˜å®šä¹‰çš„ç ä½æ˜¯ `U+10FFFF`ï¼Œå› æ­¤å¯ä»¥ä¿è¯ä»»ä½•ç ä½éƒ½é€‚åˆã€‚

UTF-16 and UTF-8 are less straightforward, but the ultimate goal is the same: to take a code point and encode it as bytes.

UTF-16 å’Œ UTF-8 ä¸é‚£ä¹ˆç›´æ¥ï¼Œä½†æœ€ç»ˆç›®æ ‡æ˜¯ç›¸åŒçš„ï¼šå°†ç ä½ä½œä¸ºå­—èŠ‚è¿›è¡Œç¼–ç ã€‚

Encoding is what youâ€™ll actually deal with as a programmer.

ä½œä¸ºç¨‹åºå‘˜ï¼Œç¼–ç æ˜¯ä½ å®é™…å¤„ç†çš„å†…å®¹ã€‚

## How many bytes are in UTF-8?

## UTF-8 ä¸­æœ‰å¤šå°‘å­—èŠ‚ï¼Ÿ

UTF-8 is a variable-length encoding. A code point might be encoded as a sequence of one to four bytes.

UTF-8 æ˜¯ä¸€ç§å˜é•¿ç¼–ç ã€‚ç ä½å¯èƒ½è¢«ç¼–ç ä¸ºä¸€ä¸ªåˆ°å››ä¸ªå­—èŠ‚çš„åºåˆ—ã€‚

This is how it works:

è¿™æ˜¯å®ƒå·¥ä½œçš„æ–¹å¼ï¼š

<table>
  <thead>
    <tr>
      <th>Code point</th>
      <th>Byte 1</th>
      <th>Byte 2</th>
      <th>Byte 3</th>
      <th>Byte 4</th>
    </tr>
  </thead>
  <thead>
    <tr>
      <th>ç ä½</th>
      <th>ç¬¬ 1 å­—èŠ‚</th>
      <th>ç¬¬ 2 å­—èŠ‚</th>
      <th>ç¬¬ 3 å­—èŠ‚</th>
      <th>ç¬¬ 4 å­—èŠ‚</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
        U+<code>0000</code>..<code>007F</code>
      </td>
      <td>
        <code>0xxxxxxx</code>
      </td>
    </tr>
    <tr>
      <td>
        U+<code>0080</code>..<code>07FF</code>
      </td>
      <td>
        <code>110xxxxx</code>
      </td>
      <td>
        <code>10xxxxxx</code>
      </td>
    </tr>
    <tr>
      <td>
        U+<code>0800</code>..<code>FFFF</code>
      </td>
      <td>
        <code>1110xxxx</code>
      </td>
      <td>
        <code>10xxxxxx</code>
      </td>
      <td>
        <code>10xxxxxx</code>
      </td>
    </tr>
    <tr>
      <td>
        U+<code>10000</code>..<code>10FFFF</code>
      </td>
      <td>
        <code>11110xxx</code>
      </td>
      <td>
        <code>10xxxxxx</code>
      </td>
      <td>
        <code>10xxxxxx</code>
      </td>
      <td>
        <code>10xxxxxx</code>
      </td>
    </tr>
  </tbody>
</table>

If you combine this with the Unicode table, youâ€™ll see that English is encoded with 1 byte, Cyrillic, Latin European languages, Hebrew and Arabic need 2, and Chinese, Japanese, Korean, other Asian languages, and Emoji need 3 or 4.

å°†æ­¤ä¸ Unicode è¡¨ç»“åˆèµ·æ¥ï¼Œå°±å¯ä»¥çœ‹åˆ°è‹±è¯­ä½¿ç”¨ 1 ä¸ªå­—èŠ‚è¿›è¡Œç¼–ç ï¼Œè¥¿é‡Œå°”è¯­ã€æ‹‰ä¸è¯­ã€å¸Œä¼¯æ¥è¯­å’Œé˜¿æ‹‰ä¼¯è¯­éœ€è¦ 2 ä¸ªå­—èŠ‚ï¼Œä¸­æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ã€å…¶ä»–äºšæ´²è¯­è¨€å’Œ Emoji éœ€è¦ 3 ä¸ªæˆ– 4 ä¸ªå­—èŠ‚ã€‚

A few important points here:

è¿™é‡Œæœ‰å‡ ä¸ªè¦ç‚¹ï¼š

First, UTF-8 is byte-compatible with ASCII. The code points 0..127, the former ASCII, are encoded with one byte, and itâ€™s the same exact byte. `U+0041` (`A`, Latin Capital Letter A) is just `41`, one byte.

ç¬¬ä¸€ï¼ŒUTF-8 ä¸ ASCII å…¼å®¹ã€‚ç ä½ 0..127ï¼Œå³ ASCIIï¼Œä½¿ç”¨ä¸€ä¸ªå­—èŠ‚è¿›è¡Œç¼–ç ï¼Œè€Œä¸”æ˜¯å®Œå…¨ç›¸åŒçš„å­—èŠ‚ã€‚`U+0041` (`A`ï¼Œæ‹‰ä¸å¤§å†™å­—æ¯ A) åªæ˜¯ `41`ï¼Œä¸€ä¸ªå­—èŠ‚ã€‚

Any pure ASCII text is also a valid UTF-8 text, and any UTF-8 text that only uses codepoints 0..127 can be read as ASCII directly.

ä»»ä½•çº¯ ASCII æ–‡æœ¬ä¹Ÿæ˜¯æœ‰æ•ˆçš„ UTF-8 æ–‡æœ¬ï¼Œä»»ä½•åªä½¿ç”¨ç ä½ 0..127 çš„ UTF-8 æ–‡æœ¬éƒ½å¯ä»¥ç›´æ¥è¯»å–ä¸º ASCIIã€‚

Second, UTF-8 is space-efficient for basic Latin. That was one of its main selling points over UTF-16. It might not be fair for texts all over the world, but for technical strings like HTML tags or JSON keys, it makes sense.

ç¬¬äºŒï¼ŒUTF-8 å¯¹äºåŸºæœ¬æ‹‰ä¸è¯­æ¥è¯´å¯ä»¥èŠ‚çœç©ºé—´ã€‚è¿™æ˜¯å®ƒæ¯” UTF-16 çš„ä¸»è¦å–ç‚¹ä¹‹ä¸€ã€‚å¯¹äºä¸–ç•Œå„åœ°çš„æ–‡æœ¬æ¥è¯´å¯èƒ½ä¸å…¬å¹³ï¼Œä½†å¯¹äº HTML æ ‡ç­¾æˆ– JSON é”®ç­‰æŠ€æœ¯å­—ç¬¦ä¸²æ¥è¯´æ˜¯æœ‰æ„ä¹‰çš„ã€‚

On average, UTF-8 tends to be a pretty good deal, even for non-English computers. And for English, thereâ€™s no comparison.

å¹³å‡è€Œè¨€ï¼ŒUTF-8 å¾€å¾€æ˜¯ä¸€ä¸ªç›¸å½“ä¸é”™çš„é€‰æ‹©ï¼Œå³ä½¿å¯¹äºä½¿ç”¨éè‹±è¯­çš„è®¡ç®—æœºä¹Ÿæ˜¯å¦‚æ­¤ã€‚è€Œå¯¹äºè‹±è¯­è€Œè¨€ï¼Œæ²¡æœ‰æ¯”å®ƒæ›´å¥½çš„é€‰æ‹©äº†ã€‚

Third, UTF-8 has error detection and recovery built-in. The first byteâ€™s prefix always looks different from bytes 2-4. This way you can always tell if you are looking at a complete and valid sequence of UTF-8 bytes or if something is missing (for example, you jumped it the middle of the sequence).
Then you can correct that by moving forward or backward until you find the beginning of the correct sequence.

ç¬¬ä¸‰ï¼ŒUTF-8 è‡ªå¸¦é”™è¯¯æ£€æµ‹å’Œé”™è¯¯æ¢å¤çš„åŠŸèƒ½ã€‚ç¬¬ä¸€ä¸ªå­—èŠ‚çš„å‰ç¼€æ€»æ˜¯ä¸ç¬¬ 2-4 ä¸ªå­—èŠ‚ä¸åŒï¼Œå› è€Œä½ æ€»æ˜¯å¯ä»¥åˆ¤æ–­ä½ æ˜¯å¦æ­£åœ¨æŸ¥çœ‹å®Œæ•´ä¸”æœ‰æ•ˆçš„ UTF-8 å­—èŠ‚åºåˆ—ï¼Œæˆ–è€…æ˜¯å¦ç¼ºå°‘æŸäº›å†…å®¹ï¼ˆä¾‹å¦‚ï¼Œä½ è·³åˆ°äº†åºåˆ—çš„ä¸­é—´ï¼‰ã€‚ç„¶åä½ å°±å¯ä»¥é€šè¿‡å‘å‰æˆ–å‘åç§»åŠ¨ï¼Œç›´åˆ°æ‰¾åˆ°æ­£ç¡®åºåˆ—çš„å¼€å¤´æ¥çº æ­£å®ƒã€‚

And a couple of important consequences:

è¿™å¸¦æ¥äº†ä¸€äº›é‡è¦çš„ç»“è®ºï¼š

- You CANâ€™T determine the length of the string by counting bytes.
- ä½ **ä¸èƒ½**é€šè¿‡è®¡æ•°å­—èŠ‚æ¥ç¡®å®šå­—ç¬¦ä¸²çš„é•¿åº¦ã€‚
- You CANâ€™T randomly jump into the middle of the string and start reading.
- ä½ **ä¸èƒ½**éšæœºè·³åˆ°å­—ç¬¦ä¸²çš„ä¸­é—´å¹¶å¼€å§‹è¯»å–ã€‚
- You CANâ€™T get a substring by cutting at arbitrary byte offsets. You might cut off part of the character.
- ä½ **ä¸èƒ½**é€šè¿‡åœ¨ä»»æ„å­—èŠ‚åç§»å¤„åˆ‡å‰²æ¥è·å–å­å­—ç¬¦ä¸²ã€‚ä½ å¯èƒ½ä¼šåˆ‡æ‰å­—ç¬¦çš„ä¸€éƒ¨åˆ†ã€‚

Those who do will eventually meet this bad boy: ï¿½

è¯•å›¾è¿™æ ·åšçš„äººæœ€ç»ˆä¼šé‡åˆ°è¿™ä¸ªåå°å­ï¼šï¿½

## Whatâ€™s ï¿½?

## ï¿½ æ˜¯ä»€ä¹ˆï¼Ÿ

`U+FFFD`, the Replacement Character, is simply another code point in the Unicode table. Apps and libraries can use it when they detect Unicode errors.

`U+FFFD`ï¼Œ<dfn>æ›¿æ¢å­—ç¬¦</dfn>ï¼Œåªæ˜¯ Unicode è¡¨ä¸­çš„å¦ä¸€ä¸ªç ä½ã€‚å½“åº”ç”¨ç¨‹åºå’Œåº“æ£€æµ‹åˆ° Unicode é”™è¯¯æ—¶ï¼Œå®ƒä»¬å¯ä»¥ä½¿ç”¨å®ƒã€‚

If you cut half of the code point off, thereâ€™s not much left to do with the other half, except displaying an error. Thatâ€™s when ï¿½ is used.

å¦‚æœä½ åˆ‡æ‰äº†ç ä½çš„ä¸€åŠï¼Œé‚£å°±æ²¡æœ‰ä»€ä¹ˆå…¶ä»–åŠæ³•ï¼Œåªèƒ½æ˜¾ç¤ºé”™è¯¯äº†ã€‚è¿™å°±æ˜¯ä½¿ç”¨ ï¿½ çš„æ—¶å€™ã€‚

<Code
  lang="js"
  code={`var bytes = "ĞĞ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ°".getBytes("UTF-8");
var partial = Arrays.copyOfRange(bytes, 0, 11);
new String(partial, "UTF-8"); // => "ĞĞ½Ğ°Ğ»ï¿½"`}
/>

## Wouldnâ€™t UTF-32 be easier for everything?

## ä½¿ç”¨ UTF-32 ä¸ä¼šè®©ä¸€åˆ‡å˜å¾—æ›´å®¹æ˜“å—ï¼Ÿ

NO.

ä¸ä¼šã€‚

UTF-32 is great for operating on code points. Indeed, if every code point is always 4 bytes, then `strlen(s) == sizeof(s) / 4`, `substring(0, 3) == bytes[0, 12]`, etc.

UTF-32 å¯¹äºæ“ä½œç ä½å¾ˆæ£’ã€‚ç¡®å®ï¼Œå¦‚æœæ¯ä¸ªç ä½æ€»æ˜¯ 4 ä¸ªå­—èŠ‚ï¼Œé‚£ä¹ˆ `strlen(s) == sizeof(s) / 4`ï¼Œ`substring(0, 3) == bytes[0, 12]`ï¼Œç­‰ç­‰ã€‚

The problem is, you donâ€™t want to operate on code points. A code point is not a unit of writing; one code point is not always a single character. What you should be iterating on is called â€œ**extended grapheme clusters**â€, or graphemes for short.

é—®é¢˜æ˜¯ï¼Œä½ æƒ³æ“ä½œçš„å¹¶éç ä½ã€‚ç ä½ä¸æ˜¯ä¹¦å†™çš„å•ä½ï¼›ä¸€ä¸ªç ä½ä¸æ€»æ˜¯ä¸€ä¸ªå­—ç¬¦ã€‚ä½ åº”è¯¥è¿­ä»£çš„æ˜¯å«åšã€Œ**<dfn>æ‰©å±•å­—ä½ç°‡</dfn>**ï¼ˆextended grapheme clusterï¼‰ã€çš„ä¸œè¥¿ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œç®€ç§°å­—ä½ã€‚

A grapheme is a minimally distinctive unit of writing in the context of a particular writing system. `Ã¶` is one grapheme. `eÌ` is one too. And `ê°`. Basically, grapheme is what the user thinks of as a single character.

<dfn>å­—ä½</dfn>ï¼ˆgraphemeï¼Œæˆ–è¯‘ä½œå­—ç´ ï¼‰[^1]æ˜¯åœ¨ç‰¹å®šä¹¦å†™ç³»ç»Ÿçš„ä¸Šä¸‹æ–‡ä¸­æœ€å°çš„å¯åŒºåˆ†çš„ä¹¦å†™å•ä½ã€‚`Ã¶` æ˜¯ä¸€ä¸ªå­—ä½ã€‚`eÌ`ã€`ê°` ä¹Ÿæ˜¯ã€‚åŸºæœ¬ä¸Šï¼Œå­—ä½æ˜¯ç”¨æˆ·è®¤ä¸ºæ˜¯å•ä¸ªå­—ç¬¦çš„ä¸œè¥¿ã€‚

[^1]: [<dfn>å­—ä½</dfn>](https://zh.wikipedia.org/wiki/%E5%AD%97%E4%BD%8D)åˆç§°å½¢ç´ ã€å­—ç´ ï¼Œæ˜¯æœ€å°çš„æœ‰æ„ä¹‰ä¹¦å†™ç¬¦å·å•ä½ï¼›æ­¤æœ¯è¯­æ˜¯ç”±è¯­éŸ³å­¦é‡Œçš„ã€ŒéŸ³ä½ï¼ˆéŸ³ç´ ï¼‰ã€ç±»æ¨åˆ°æ–‡å­—å­¦çš„ã€‚

The problem is, in Unicode, some graphemes are encoded with multiple code points!

é—®é¢˜æ˜¯ï¼Œåœ¨ Unicode ä¸­ï¼Œä¸€äº›å­—ä½ä½¿ç”¨å¤šä¸ªç ä½è¿›è¡Œç¼–ç ï¼

<Img src="graphemes@2x.png" width="600" height="340" />

For example, `eÌ` (a single grapheme) is encoded in Unicode as `e` (U+0065 Latin Small Letter E) + `Â´` (U+0301 Combining Acute Accent). Two code points!

æ¯”å¦‚è¯´ï¼Œ`eÌ`ï¼ˆä¸€ä¸ªå•ç‹¬çš„å­—ä½ï¼‰åœ¨ Unicode ä¸­è¢«ç¼–ç ä¸º `e`ï¼ˆU+0065 æ‹‰ä¸å°å†™å­—æ¯ Eï¼‰+ `Â´`ï¼ˆU+0301 è¿æ¥é‡éŸ³ç¬¦ï¼‰ã€‚ä¸¤ä¸ªç ä½ï¼

It can also be more than two:

å®ƒä¹Ÿå¯ä»¥æ˜¯ä¸¤ä¸ªä»¥ä¸Šï¼š

- <code class="emoji">â˜¹ï¸</code> is `U+2639` + `U+FE0F`
- <code class="emoji">â˜¹ï¸</code> æ˜¯ `U+2639` + `U+FE0F`
- <code class="emoji">ğŸ‘¨â€ğŸ­</code> is `U+1F468` + `U+200D` + `U+1F3ED`
- <code class="emoji">ğŸ‘¨â€ğŸ­</code> æ˜¯ `U+1F468` + `U+200D` + `U+1F3ED`
- <code class="emoji">ğŸšµğŸ»â€â™€ï¸</code> is `U+1F6B5` + `U+1F3FB` + `U+200D` + `U+2640` + `U+FE0F`
- <code class="emoji">ğŸšµğŸ»â€â™€ï¸</code> æ˜¯ `U+1F6B5` + `U+1F3FB` + `U+200D` + `U+2640` + `U+FE0F`
- `yÌ–Ì ÍÌ˜Í‡Í—ÌÌ½ÌÍ` is `U+0079` + `U+0316` + `U+0320` + `U+034D` + `U+0318` + `U+0347` + `U+0357` + `U+030F` + `U+033D` + `U+030E` + `U+035E`
- `yÌ–Ì ÍÌ˜Í‡Í—ÌÌ½ÌÍ` æ˜¯ `U+0079` + `U+0316` + `U+0320` + `U+034D` + `U+0318` + `U+0347` + `U+0357` + `U+030F` + `U+033D` + `U+030E` + `U+035E`

Thereâ€™s no limit, as far as I know.

æ®æˆ‘æ‰€çŸ¥ï¼Œæ²¡æœ‰é™åˆ¶ã€‚

Remember, we are talking about code points here. Even in the widest encoding, UTF-32, <code class="emoji">ğŸ‘¨â€ğŸ­</code> will still take three 4-byte units to encode. And it still needs to be treated as a single character.

è®°ä½ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œè°ˆè®ºçš„æ˜¯ç ä½ã€‚å³ä½¿åœ¨æœ€å®½çš„ç¼–ç  UTF-32 ä¸­ï¼Œ<code class="emoji">ğŸ‘¨â€ğŸ­</code> ä»ç„¶éœ€è¦ä¸‰ä¸ª 4 å­—èŠ‚å•å…ƒæ¥ç¼–ç ã€‚å®ƒä»ç„¶éœ€è¦è¢«è§†ä¸ºä¸€ä¸ªå•ç‹¬çš„å­—ç¬¦ã€‚

If the analogy helps, we can think of the Unicode itself (without any encodings) as being variable-length.

å¦‚æœè¿™ä¸ªç±»æ¯”æœ‰å¸®åŠ©çš„è¯ï¼Œæˆ‘ä»¬å¯ä»¥è®¤ä¸º Unicode æœ¬èº«ï¼ˆæ²¡æœ‰ä»»ä½•ç¼–ç ï¼‰æ˜¯å˜é•¿çš„ã€‚

<Loud
en={`An Extended Grapheme Cluster is a sequence of one or more Unicode code points that must be treated as a single, unbreakable character.`}
>ä¸€ä¸ªæ‰©å±•å­—ä½ç°‡æ˜¯ä¸€ä¸ªæˆ–å¤šä¸ª Unicode ç ä½çš„åºåˆ—ï¼Œå¿…é¡»è¢«è§†ä¸ºä¸€ä¸ªå•ç‹¬çš„ã€ä¸å¯åˆ†å‰²çš„å­—ç¬¦ã€‚</Loud>

Therefore, we get all the problems we have with variable-length encodings, but now on code point level: you canâ€™t take only a part of the sequence, it always should be selected, copied, edited, or deleted as a whole.

å› æ­¤ï¼Œæˆ‘ä»¬ä¼šé‡åˆ°æ‰€æœ‰å˜é•¿ç¼–ç çš„é—®é¢˜ï¼Œä½†ç°åœ¨æ˜¯åœ¨ç ä½çº§åˆ«ä¸Šï¼šä½ ä¸èƒ½åªå–åºåˆ—çš„ä¸€éƒ¨åˆ†â€”â€”å®ƒæ€»æ˜¯åº”è¯¥ä½œä¸ºä¸€ä¸ªæ•´ä½“è¢«é€‰æ‹©ã€å¤åˆ¶ã€ç¼–è¾‘æˆ–åˆ é™¤ã€‚

Failure to respect grapheme clusters leads to bugs like this:

ä¸å°Šé‡å­—ä½ç°‡ä¼šå¯¼è‡´åƒè¿™æ ·çš„é”™è¯¯ï¼š

<img src="https://tonsky.me/blog/unicode/error1.png" />

or this:

æˆ–è€…è¿™æ ·ï¼š

<figure>
<video autoplay muted loop controls width="600" height="201">
  <source src="https://tonsky.me/blog/unicode/intellij@2x.mp4" type="video/mp4" />
</video>
<figcaption lang="en">Just to be clear: this is NOT correct behavior</figcaption>
<figcaption lang="zh">è®©æˆ‘ä»¬å…ˆè¯´æ¸…æ¥šï¼šè¿™<em>ä¸æ˜¯</em>æ­£ç¡®çš„è¡Œä¸º</figcaption>
</figure>

Using UTF-32 instead of UTF-8 will not make your life any easier in regards to extended grapheme clusters. And extended grapheme clusters is what you should care about.

å°±æ‰©å±•å­—ä½ç°‡è€Œè¨€ï¼Œç”¨ UTF-32 ä»£æ›¿ UTF-8 ä¸ä¼šè®©ä½ çš„ç”Ÿæ´»å˜å¾—æ›´å®¹æ˜“ã€‚è€Œæ‰©å±•å­—ä½ç°‡æ‰æ˜¯ä½ åº”è¯¥å…³å¿ƒçš„ã€‚

<Loud en="Code points â€” ğŸ¥±. Graphemes â€” ğŸ˜">ç ä½ â€” ğŸ¥±. å­—ä½ â€” ğŸ˜</Loud>

## Is Unicode hard only because of emojis?

## Unicode ä¹‹æ‰€ä»¥éš¾ï¼Œä»…ä»…æ˜¯å› ä¸ºè¡¨æƒ…ç¬¦å·å—ï¼Ÿ

Not really. Extended Grapheme Clusters are also used for alive, actively used languages. For example:

å¹¶ä¸ã€‚æ²¡æœ‰æ¶ˆäº¡çš„ã€æ´»è·ƒä½¿ç”¨çš„è¯­è¨€ä¹Ÿä½¿ç”¨æ‰©å±•å­—ä½ç°‡ã€‚ä¾‹å¦‚ï¼š

- `Ã¶` (German) is a single character, but multiple code points (`U+006F U+0308`).
- `Ã¶` (å¾·è¯­) æ˜¯ä¸€ä¸ªå•ç‹¬çš„å­—ç¬¦ï¼Œä½†æ˜¯å¤šä¸ªç ä½ï¼ˆ`U+006F U+0308`ï¼‰ã€‚
- `Ä…Ì` (Lithuanian) is `U+00E1 U+0328`.
- `Ä…Ì` (ç«‹é™¶å®›è¯­) æ˜¯ `U+00E1 U+0328`ã€‚
- `ê°` (Korean) is `U+1100 U+1161 U+11A8`.
- `ê°` (éŸ©è¯­) æ˜¯ `U+1100 U+1161 U+11A8`ã€‚

So no, itâ€™s not just about emojis.

æ‰€ä»¥ï¼Œä¸ï¼Œè¿™ä¸ä»…ä»…æ˜¯å…³äºè¡¨æƒ…ç¬¦å·ã€‚

## Whatâ€™s `"ğŸ¤¦ğŸ¼â€â™‚ï¸".length`?

## `"ğŸ¤¦ğŸ¼â€â™‚ï¸".length` æ˜¯ä»€ä¹ˆï¼Ÿ

The question is inspired by [this brilliant article](https://hsivonen.fi/string-length/).

è¿™ä¸ªé—®é¢˜çš„çµæ„Ÿæ¥è‡ªäº[è¿™ç¯‡ç²¾å½©çš„æ–‡ç« ](https://hsivonen.fi/string-length/)ã€‚

Different programming languages will happily give you different answers.

ä¸åŒçš„ç¼–ç¨‹è¯­è¨€å¾ˆä¹æ„ç»™ä½ ä¸åŒçš„ç­”æ¡ˆã€‚

<p lang="mul">Python 3:</p>

<Code
  lang="py"
  code='>>> len("ğŸ¤¦ğŸ¼â€â™‚ï¸")
5'
/>

<p lang="mul">JavaScript / Java / C#:</p>

<Code
  lang="csharp"
  code={`>> "ğŸ¤¦ğŸ¼â€â™‚ï¸".length
7`}
/>

<p lang="mul">Rust:</p>

<Code
  lang="rust"
  code={`println!("{}", "ğŸ¤¦ğŸ¼â€â™‚ï¸".len());
// => 17`}
/>

As you can guess, different languages use different internal string representations (UTF-32, UTF-16, UTF-8) and report length in whatever units they store characters in (ints, shorts, bytes).

å¦‚ä½ æ‰€æ–™ï¼Œä¸åŒçš„è¯­è¨€ä½¿ç”¨ä¸åŒçš„å†…éƒ¨å­—ç¬¦ä¸²è¡¨ç¤ºï¼ˆUTF-32ã€UTF-16ã€UTF-8ï¼‰ï¼Œå¹¶ä»¥å®ƒä»¬å­˜å‚¨å­—ç¬¦çš„ä»»ä½•å•ä½æŠ¥å‘Šé•¿åº¦ï¼ˆintã€shortã€byteï¼‰ã€‚

BUT! If you ask any normal person, one that isnâ€™t burdened with computer internals, theyâ€™ll give you a straight answer: 1. The length of <code class="emoji">ğŸ¤¦ğŸ¼â€â™‚ï¸</code> string is 1.

<b>ä½†æ˜¯ï¼</b>å¦‚æœä½ é—®ä»»ä½•æ­£å¸¸çš„äººï¼Œä¸€ä¸ªä¸è¢«è®¡ç®—æœºå†…éƒ¨æ‰€æ‹–ç´¯çš„äººï¼Œä»–ä»¬ä¼šç»™ä½ ä¸€ä¸ªç›´æ¥çš„ç­”æ¡ˆï¼š1ã€‚<code class="emoji">ğŸ¤¦ğŸ¼â€â™‚ï¸</code> å­—ç¬¦ä¸²çš„é•¿åº¦æ˜¯ 1ã€‚

Thatâ€™s what extended grapheme clusters are all about: what _humans_ perceive as a single character. And in this case, <code class="emoji">ğŸ¤¦ğŸ¼â€â™‚ï¸</code> is undoubtedly a single character.

è¿™å°±æ˜¯æ‰©å±•å­—ä½ç°‡å­˜åœ¨çš„æ„ä¹‰ï¼šäººä»¬è®¤ä¸ºæ˜¯å•ä¸ªå­—ç¬¦ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ<code class="emoji">ğŸ¤¦ğŸ¼â€â™‚ï¸</code> æ— ç–‘æ˜¯ä¸€ä¸ªå•ç‹¬çš„å­—ç¬¦ã€‚

The fact that <code class="emoji">ğŸ¤¦ğŸ¼â€â™‚ï¸</code> consists of 5 code points (`U+1F926 U+1F3FB U+200D U+2642 U+FE0F`) is mere implementation detail. It should not be broken apart, it should not be counted as multiple characters, the text cursor should not be positioned inside it, it shouldnâ€™t be partially selected, etc.

<code class="emoji">ğŸ¤¦ğŸ¼â€â™‚ï¸</code> åŒ…å« 5 ä¸ªç ä½ï¼ˆ`U+1F926 U+1F3FB U+200D U+2642 U+FE0F`ï¼‰çš„äº‹å®åªæ˜¯å®ç°ç»†èŠ‚ã€‚å®ƒä¸åº”è¯¥è¢«åˆ†å¼€ï¼Œå®ƒä¸åº”è¯¥è¢«è®¡ç®—ä¸ºå¤šä¸ªå­—ç¬¦ï¼Œæ–‡æœ¬å…‰æ ‡ä¸åº”è¯¥è¢«å®šä½åœ¨å®ƒçš„å†…éƒ¨ï¼Œå®ƒä¸åº”è¯¥è¢«éƒ¨åˆ†é€‰æ‹©ï¼Œç­‰ç­‰ã€‚

For all intents and purposes, this is an atomic unit of text. Internally, it could be encoded whatever, but for user-facing API, it should be treated as a whole.

å°±æ‰€æœ‰æ„å›¾å’Œç›®çš„è€Œè¨€ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–‡æœ¬çš„åŸå­å•ä½ã€‚åœ¨å†…éƒ¨ï¼Œå®ƒå¯ä»¥è¢«ç¼–ç ä¸ºä»»ä½•ä¸œè¥¿ï¼Œä½†å¯¹äºé¢å‘ç”¨æˆ·çš„ APIï¼Œå®ƒåº”è¯¥è¢«è§†ä¸ºä¸€ä¸ªæ•´ä½“ã€‚

The only modern language that gets it right is Swift:

å”¯ä¸€æ²¡å¼„é”™è¿™ä»¶äº‹çš„ç°ä»£è¯­è¨€æ˜¯ Swiftï¼š

<Code lang="swift" code='print("ğŸ¤¦ğŸ¼â€â™‚ï¸".count)
// => 1' />

Basically, there are two layers:

åŸºæœ¬ä¸Šï¼Œæœ‰ä¸¤å±‚ï¼š

1. Internal, computer-oriented. How to copy strings, send them over the network, store on disk, etc. This is where you need encodings like UTF-8. Swift uses UTF-8 internally, but it might as well be UTF-16 or UTF-32. What's important is that you only use it to copy strings as a whole and never to analyze their content.
1. å†…éƒ¨ï¼Œé¢å‘è®¡ç®—æœºçš„ä¸€å±‚ã€‚å¦‚ä½•å¤åˆ¶å­—ç¬¦ä¸²ã€é€šè¿‡ç½‘ç»œå‘é€å­—ç¬¦ä¸²ã€å­˜å‚¨åœ¨ç£ç›˜ä¸Šç­‰ã€‚è¿™å°±æ˜¯ä½ éœ€è¦ UTF-8 è¿™æ ·çš„ç¼–ç çš„åœ°æ–¹ã€‚Swift åœ¨å†…éƒ¨ä½¿ç”¨ UTF-8ï¼Œä½†ä¹Ÿå¯ä»¥æ˜¯ UTF-16 æˆ– UTF-32ã€‚é‡è¦çš„æ˜¯ï¼Œä½ åªä½¿ç”¨å®ƒæ¥æ•´ä½“å¤åˆ¶å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯åˆ†æå®ƒä»¬çš„å†…å®¹ã€‚
2. External, human-facing API. Character count in UI. Taking first 10 characters to generate preview. Searching in text. Methods like `.count` or `.substring`. Swift gives you _a view_ that pretends the string is a sequence of grapheme clusters. And that view behaves like any human would expect: it gives you 1 for `"ğŸ¤¦ğŸ¼â€â™‚ï¸".count`.
2. å¤–éƒ¨ï¼Œé¢å‘äººç±»çš„ API ä¸€å±‚ã€‚UI ä¸­çš„å­—æ•°ç»Ÿè®¡ã€‚è·å–å‰ 10 ä¸ªå­—ç¬¦ä»¥ç”Ÿæˆé¢„è§ˆã€‚åœ¨æ–‡æœ¬ä¸­æœç´¢ã€‚åƒ `.count` æˆ– `.substring` è¿™æ ·çš„æ–¹æ³•ã€‚Swift ç»™ä½ <em>ä¸€ä¸ªè§†å›¾</em>ï¼Œå‡è£…å­—ç¬¦ä¸²æ˜¯ä¸€ä¸ªå­—ä½ç°‡åºåˆ—ã€‚è¿™ä¸ªè§†å›¾çš„è¡Œä¸ºå°±åƒä»»ä½•äººæ‰€æœŸæœ›çš„é‚£æ ·ï¼šå®ƒä¸º `"ğŸ¤¦ğŸ¼â€â™‚ï¸".count` ç»™å‡º 1ã€‚

I hope more languages adopt this design soon.

æˆ‘å¸Œæœ›æ›´å¤šçš„è¯­è¨€å°½å¿«é‡‡ç”¨è¿™ç§è®¾è®¡ã€‚

Question to the reader: what to you think `"áº‡Í“ÌÍ’ÍŸÍ¡Ç«Ì Ì Ì‰ÌÍ Í¡Í…rÌ¬ÌºÍšÌÍ›Ì”Í’Í¢dÌ ÍÌ—Ì³Í‡Í†Ì‹ÌŠÍ‚Í".length` should be?

ç»™è¯»è€…çš„é—®é¢˜ï¼šä½ è®¤ä¸º `"áº‡Í“ÌÍ’ÍŸÍ¡Ç«Ì Ì Ì‰ÌÍ Í¡Í…rÌ¬ÌºÍšÌÍ›Ì”Í’Í¢dÌ ÍÌ—Ì³Í‡Í†Ì‹ÌŠÍ‚Í".length` åº”è¯¥æ˜¯ä»€ä¹ˆï¼Ÿ

## How do I detect extended grapheme clusters then?

## å¦‚ä½•æ£€æµ‹æ‰©å±•å­—ä½ç°‡ï¼Ÿ

Unfortunately, most languages choose the easy way out and let you iterate through strings with 1-2-4-byte chunks, but not with grapheme clusters.

ä¸å¹¸çš„æ˜¯ï¼Œå¤§å¤šæ•°è¯­è¨€éƒ½é€‰æ‹©äº†ç®€å•çš„æ–¹æ³•ï¼Œè®©ä½ é€šè¿‡ 1-2-4 å­—èŠ‚å—è¿­ä»£å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯é€šè¿‡å­—ä½ç°‡ã€‚

It makes no sense and has no semantics, but since itâ€™s the default, programmers donâ€™t think twice, and we see corrupted strings as the result:

è¿™æ²¡æœ‰æ„ä¹‰ï¼Œä¹Ÿä¸åˆè¯­ä¹‰ï¼Œä½†ç”±äºå®ƒæ˜¯ç¼ºçœå€¼ï¼Œç¨‹åºå‘˜ä¸ä¼šå†è€ƒè™‘ï¼Œæˆ‘ä»¬çœ‹åˆ°çš„ç»“æœæ˜¯æŸåçš„å­—ç¬¦ä¸²ï¼š

![](https://tonsky.me/blog/unicode/stdlib@2x.png)

â€œI know, Iâ€™ll use a library to do strlen()!â€ â€” nobody, ever.

ã€Œæˆ‘çŸ¥é“ï¼Œæˆ‘ä¼šä½¿ç”¨ä¸€ä¸ªåº“æ¥åš strlen()ï¼ã€â€”â€”ä»æ¥æ²¡æœ‰äººè¿™æ ·æƒ³ã€‚

But thatâ€™s exactly what you should be doing! Use a proper Unicode library! Yes, for basic stuff like `strlen` or `indexOf` or `substring`!

ä½†è¿™æ­£æ˜¯ä½ åº”è¯¥åšçš„ï¼ä½¿ç”¨ä¸€ä¸ªåˆé€‚çš„ Unicode åº“ï¼æ˜¯çš„ï¼Œå¯¹äºåƒ `strlen` æˆ– `indexOf` æˆ– `substring` è¿™æ ·çš„åŸºæœ¬åŠŸèƒ½ï¼

For example:

ä¾‹å¦‚ï¼š

1. C/C++/Java: use [ICU](https://github.com/unicode-org/icu). Itâ€™s a library from Unicode itself that encodes all the rules about text segmentation.
1. C/C++/Java: ä½¿ç”¨ [ICU](https://github.com/unicode-org/icu)ã€‚å®ƒæ˜¯ä¸€ä¸ªæ¥è‡ª Unicode è‡ªèº«çš„åº“ï¼Œå®ƒå¯¹æ–‡æœ¬åˆ†å‰²çš„æ‰€æœ‰è§„åˆ™è¿›è¡Œç¼–ç ã€‚
2. C#: use <code style="color: #E81A1A;">TextElementEnumerator</code>, which is kept up to date with Unicode as far as I can tell.
2. C#: ä½¿ç”¨ <code style="color: #E81A1A;">TextElementEnumerator</code>ï¼Œæ®æˆ‘æ‰€çŸ¥ï¼Œå®ƒä¸ Unicode ä¿æŒæœ€æ–°ã€‚
3. Swift: just stdlib. Swift does the right thing by default.
3. Swift: æ ‡å‡†åº“å°±è¡Œã€‚Swift é»˜è®¤å°±åšå¾—å¾ˆå¥½ã€‚
4. UPD: Erlang/Elixir seem to be doing the right thing, too.
4. UPDï¼šErlang/Elixir ä¼¼ä¹ä¹Ÿåšå¾—å¾ˆå¥½ã€‚
5. For other languages, thereâ€™s probably a library or binding for ICU.
5. å¯¹äºå…¶ä»–è¯­è¨€ï¼Œå¯èƒ½æœ‰ä¸€ä¸ª ICU çš„åº“æˆ–ç»‘å®šã€‚
6. Roll your own. Unicode [publishes](https://www.unicode.org/reports/tr29/#Grapheme_Cluster_Boundaries) rules and tables in a machine-readable format, and all the libraries above are based on them.
6. è‡ªå·±åŠ¨æ‰‹ã€‚Unicode [å‘å¸ƒ](https://www.unicode.org/reports/tr29/#Grapheme_Cluster_Boundaries)äº†æœºå™¨å¯è¯»çš„è§„åˆ™å’Œè¡¨æ ¼ï¼Œä¸Šé¢çš„æ‰€æœ‰åº“éƒ½æ˜¯åŸºäºå®ƒä»¬çš„ã€‚

But whatever you choose, make sure itâ€™s on the recent enough version of Unicode (15.1 at the moment of writing), because the definition of graphemes changes from version to version. For example, Javaâ€™s `java.text.BreakIterator` is a no-go: itâ€™s based on a very old version of Unicode and not updated.

ä¸è¿‡æ— è®ºä½ é€‰å“ªä¸ªï¼Œéƒ½è¦ç¡®ä¿å®ƒæ˜¯æœ€è¿‘çš„ Unicode ç‰ˆæœ¬ï¼ˆç›®å‰æ˜¯ 15.1ï¼‰ï¼Œå› ä¸ºå­—ä½ç°‡çš„å®šä¹‰ä¼šéšç€ç‰ˆæœ¬çš„å˜åŒ–è€Œå˜åŒ–ã€‚ä¾‹å¦‚ï¼ŒJava çš„ `java.text.BreakIterator` æ˜¯ä¸è¡Œçš„ï¼šå®ƒæ˜¯åŸºäºä¸€ä¸ªéå¸¸æ—§çš„ Unicode ç‰ˆæœ¬ï¼Œè€Œä¸”æ²¡æœ‰æ›´æ–°ã€‚

<Loud en="Use a library">ç”¨ä¸ªåº“</Loud>

IMO, the whole situation is a shame. Unicode should be in the stdlib of every language by default. Itâ€™s the lingua franca of the internet! Itâ€™s not even new: weâ€™ve been living with Unicode for 20 years now.

æˆ‘è§‰å¾—ï¼Œæ•´ä¸ªæƒ…å†µéƒ½ä»¤äººé—æ†¾ã€‚Unicode åº”è¯¥æ˜¯æ¯ç§è¯­è¨€çš„æ ‡å‡†åº“ã€‚è¿™æ˜¯äº’è”ç½‘çš„é€šç”¨è¯­è¨€ï¼å®ƒç”šè‡³ä¸æ˜¯ä»€ä¹ˆæ–°é²œç©æ„å„¿ï¼šæˆ‘ä»¬å·²ç»ä¸ Unicode ç”Ÿæ´»äº† 20 å¹´äº†ã€‚

## Wait, rules are changing?

## ç­‰ä¸‹ï¼Œè§„åˆ™ä¸€ç›´å˜åŒ–ï¼Ÿ

Yes! Ainâ€™t it cool?

æ˜¯çš„ï¼å¾ˆé…·å§ï¼Ÿ

(I know, it ainâ€™t)

ï¼ˆæˆ‘çŸ¥é“ï¼Œå®ƒä¸æ˜¯ï¼‰

Starting roughly in 2014, Unicode has been releasing a major revision of their standard every year. This is where you get your new emojis from â€” Android and iOS updates in the Fall usually include the newest Unicode standard among other things.

å¤§æ¦‚ä» 2014 å¹´å¼€å§‹ï¼ŒUnicode æ¯å¹´éƒ½ä¼šå‘å¸ƒä¸€æ¬¡ä¸»è¦ä¿®è®¢ç‰ˆã€‚è¿™å°±æ˜¯ä½ è·å¾—æ–°çš„ emoji çš„åœ°æ–¹â€”â€”Android å’Œ iOS çš„æ›´æ–°é€šå¸¸åŒ…æ‹¬æœ€æ–°çš„ Unicode æ ‡å‡†ã€‚

<Img src="https://tonsky.me/blog/unicode/versions@2x.png" width="300" height="620" />

Whatâ€™s sad for us is that the rules defining grapheme clusters change every year as well. What is considered a sequence of two or three separate code points today might become a grapheme cluster tomorrow! Thereâ€™s no way to know! Or prepare!

å¯¹æˆ‘ä»¬æ¥è¯´å¯æ‚²çš„æ˜¯å®šä¹‰å­—ä½ç°‡çš„è§„åˆ™ä¹Ÿåœ¨æ¯å¹´å˜åŒ–ã€‚ä»Šå¤©è¢«è®¤ä¸ºæ˜¯ä¸¤ä¸ªæˆ–ä¸‰ä¸ªå•ç‹¬ç ä½çš„åºåˆ—ï¼Œæ˜å¤©å¯èƒ½å°±æˆä¸ºå­—ä½ç°‡ï¼æˆ‘ä»¬æ— ä»å¾—çŸ¥ï¼Œæ²¡æ³•å‡†å¤‡ï¼

Even worse, different versions of your own app might be running on different Unicode standards and report different string lengths!

æ›´ç³Ÿç³•çš„æ˜¯ï¼Œä½ è‡ªå·±çš„åº”ç”¨ç¨‹åºçš„ä¸åŒç‰ˆæœ¬å¯èƒ½åœ¨ä¸åŒçš„ Unicode æ ‡å‡†ä¸Šè¿è¡Œï¼Œå¹¶ç»™å‡ºä¸åŒçš„å­—ç¬¦ä¸²é•¿åº¦ï¼

But thatâ€™s the reality we live in. You donâ€™t really have a choice here. You canâ€™t ignore Unicode or Unicode updates if you want to stay relevant and provide a decent user experience. So, buckle up, embrace, and update.

ä½†è¿™å°±æ˜¯æˆ‘ä»¬æ‰€ç”Ÿæ´»çš„ç°å®â€”â€”ä½ å®é™…ä¸Šåˆ«æ— é€‰æ‹©ã€‚å¦‚æœä½ æƒ³ç«™ç¨³è„šè·Ÿå¹¶æä¾›è‰¯å¥½çš„ç”¨æˆ·ä½“éªŒï¼Œå°±ä¸èƒ½å¿½ç•¥ Unicode æˆ– Unicode æ›´æ–°ã€‚æ‰€ä»¥ï¼Œå¯„å¥½å®‰å…¨å¸¦ï¼Œæ‹¥æŠ±æ›´æ–°ã€‚

<Loud en="Update yearly">æ¯å¹´æ›´æ–°</Loud>

## Why is "AÌŠ" !== "Ã…" !== "â„«"?

## ä¸ºä»€ä¹ˆ `"AÌŠ" !== "Ã…" !== "â„«"`ï¼Ÿ

![](https://tonsky.me/blog/unicode/spider_men@2x.jpg)

Copy any of these to your JavaScript console:

è¯·å°†ä¸‹é¢ä»»ä½•ä¸€è¡Œå¤åˆ¶åˆ°ä½ çš„ JavaScript æ§åˆ¶å°ï¼š

<Code
  code={`"AÌŠ" === "Ã…";
"Ã…" === "â„«";
"AÌŠ" === "â„«";`}
  lang="js"
/>

What do you get? False? You should get false, and itâ€™s not a mistake.

ä½ å¾—åˆ°äº†ä»€ä¹ˆï¼ŸFalseï¼Ÿç¡®å®æ˜¯ <samp>false</samp>ï¼Œå¹¶ä¸”è¿™ä¸æ˜¯ä¸€ä¸ªé”™è¯¯ã€‚

Remember earlier when I said that `Ã¶` is two code points, `U+006F U+0308`? Basically, Unicode offers more than one way to write characters like `Ã¶` or `Ã…`. You can:

è¿˜è®°å¾—æˆ‘ä¹‹å‰è¯´è¿‡ `Ã¶` æ˜¯ä¸¤ä¸ªç ä½ï¼Œ`U+006F U+0308` å—ï¼ŸåŸºæœ¬ä¸Šï¼ŒUnicode æä¾›äº†å¤šç§å†™æ³•ï¼Œæ¯”å¦‚ `Ã¶` æˆ– `Ã…`ã€‚ä½ å¯ä»¥ï¼š

1. Compose `Ã…` from normal Latin `A` + a combining character,
1. ä»æ™®é€šæ‹‰ä¸å­—æ¯ `A` + ä¸€ä¸ªè¿æ¥å­—ç¬¦ç»„åˆå‡º `Ã…`ï¼Œ
2. OR thereâ€™s also a pre-composed code point `U+00C5` that does that for you.
2. <em>æˆ–è€…</em>è¿˜æœ‰ä¸€ä¸ªé¢„ç»„åˆçš„ç ä½ `U+00C5` å¸®ä½ åšäº†è¿™ä»¶äº‹ã€‚

They will look the same (`AÌŠ` vs `Ã…`), they should work the same, and for all intents and purposes, they are considered exactly the same. The only difference is the byte representation.

ä»–ä»¬å°†ä¼šçœ‹èµ·æ¥ä¸€æ ·ï¼ˆ`AÌŠ` vs `Ã…`ï¼‰ï¼Œå®ƒä»¬åº”è¯¥ç”¨èµ·æ¥ä¸€æ ·ï¼Œå¹¶ä¸”å°±æ‰€æœ‰æ„å›¾å’Œç›®çš„è€Œè¨€ï¼Œå®ƒä»¬è¢«è®¤ä¸ºæ˜¯å®Œå…¨ç›¸åŒçš„ã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯å­—èŠ‚è¡¨ç¤ºã€‚

Thatâ€™s why we need normalization. There are four forms:

è¿™å°±æ˜¯æˆ‘ä»¬éœ€è¦å½’ä¸€åŒ–çš„åŸå› ã€‚æœ‰å››ç§å½¢å¼ï¼š

**NFD** tries to explode everything to the smallest possible pieces, and also sorts pieces in a canonical order if there is more than one.

**NFD** å°è¯•å°†æ‰€æœ‰ä¸œè¥¿éƒ½åˆ†è§£ä¸ºæœ€å°çš„å¯èƒ½éƒ¨åˆ†ï¼Œå¹¶ä¸”å¦‚æœæœ‰å¤šä¸ªéƒ¨åˆ†ï¼Œåˆ™æŒ‰ç…§è§„èŒƒé¡ºåºå¯¹éƒ¨åˆ†è¿›è¡Œæ’åºã€‚

**NFC**, on the other hand, tries to combine everything into pre-composed form if one exists.

**NFC**ï¼Œå¦ä¸€æ–¹é¢ï¼Œå°è¯•å°†æ‰€æœ‰ä¸œè¥¿ç»„åˆæˆå­˜åœ¨çš„é¢„ç»„åˆå½¢å¼ã€‚

![](https://tonsky.me/blog/unicode/normalization@2x.png)

For some characters there are also multiple versions of them in Unicode. For example, thereâ€™s `U+00C5 Latin Capital Letter A with Ring Above`, but thereâ€™s also `U+212B Angstrom Sign` which looks the same.

å¯¹äºæŸäº›å­—ç¬¦ï¼Œå®ƒä»¬åœ¨ Unicode ä¸­ä¹Ÿæœ‰å¤šä¸ªç‰ˆæœ¬ã€‚ä¾‹å¦‚ï¼Œæœ‰ `U+00C5 Latin Capital Letter A with Ring Above`ï¼Œä½†ä¹Ÿæœ‰ `U+212B Angstrom Sign`ï¼Œå®ƒçœ‹èµ·æ¥æ˜¯ä¸€æ ·çš„ã€‚

These are also replaced during normalization:

è¿™äº›ä¹Ÿåœ¨å½’ä¸€åŒ–è¿‡ç¨‹ä¸­è¢«æ›¿æ¢æ‰äº†ï¼š

![](https://tonsky.me/blog/unicode/normalization_clones@2x.png)

NFD and NFC are called â€œcanonical normalizationâ€. Another two forms are â€œcompatibility normalizationâ€:

NFD å’Œ NFC è¢«ç§°ä¸ºã€Œè§„èŒƒå½’ä¸€åŒ–ã€ã€‚å¦å¤–ä¸¤ç§å½¢å¼æ˜¯ã€Œå…¼å®¹å½’ä¸€åŒ–ã€ï¼š

**NFKD** tries to explode everything and replaces visual variants with default ones.

**NFKD** å°è¯•å°†æ‰€æœ‰ä¸œè¥¿åˆ†è§£å¼€æ¥ï¼Œå¹¶ç”¨é»˜è®¤çš„æ›¿æ¢è§†è§‰å˜ä½“ã€‚

**NFKC** tries to combine everything while replacing visual variants with default ones.

**NFKC** å°è¯•å°†æ‰€æœ‰ä¸œè¥¿ç»„åˆèµ·æ¥ï¼ŒåŒæ—¶ç”¨é»˜è®¤çš„æ›¿æ¢è§†è§‰å˜ä½“ã€‚

![](https://tonsky.me/blog/unicode/normalization_compat@2x.png)

Visual variants are separate Unicode code points that represent the same character but are supposed to render differently. Like, `â‘ ` or `â¹` or `ğ•`. We want to be able to find both `"x"` and `"2"` in a string like `"ğ•Â²"`, donâ€™t we?

<dfn>è§†è§‰å˜ä½“</dfn>æ˜¯è¡¨ç¤ºç›¸åŒå­—ç¬¦çš„å•ç‹¬çš„ Unicode ç ä½ï¼Œä½†æ˜¯åº”è¯¥å‘ˆç°ä¸åŒã€‚æ¯”å¦‚ `â‘ ` æˆ– `â¹` æˆ– `ğ•`ã€‚æˆ‘ä»¬æƒ³è¦åœ¨åƒ `"ğ•Â²"` è¿™æ ·çš„å­—ç¬¦ä¸²ä¸­æ‰¾åˆ° `"x"` å’Œ `"2"`ï¼Œä¸æ˜¯å—ï¼Ÿ

<Img src="https://tonsky.me/blog/unicode/x_variants@2x.png"
width="438" height="185" 
zhcap="æ‰€æœ‰è¿™äº›å­—ç¬¦éƒ½æœ‰å®ƒä»¬è‡ªå·±çš„ç ä½ï¼Œä½†å®ƒä»¬ä¹Ÿéƒ½æ˜¯ X"
encap="All of these have their own code points, but they are also all Xs" />

Why does the `ï¬` ligature even have its own code point? No idea. A lot can happen in a million characters.

ä¸ºä»€ä¹ˆè¿ `ï¬` è¿™ä¸ªè¿å­—éƒ½æœ‰å®ƒè‡ªå·±çš„ç ä½ï¼Ÿä¸çŸ¥é“ã€‚åœ¨ä¸€ç™¾ä¸‡ä¸ªå­—ç¬¦ä¸­ä¼šå‘ç”Ÿå¾ˆå¤šäº‹æƒ…ã€‚

<Loud en="Before comparing strings or searching for a substring, normalize!">åœ¨æ¯”è¾ƒå­—ç¬¦ä¸²æˆ–æœç´¢å­å­—ç¬¦ä¸²ä¹‹å‰ï¼Œå½’ä¸€åŒ–ï¼</Loud>

## Unicode is locale-dependent

## Unicode æ˜¯åŸºäºåŒºåŸŸè®¾ç½®çš„

The Russian name Nikolay is written like this:

ä¿„è¯­åå­— Nikolay çš„å†™æ³•å¦‚ä¸‹ï¼š

![](https://tonsky.me/blog/unicode/nikolay_ru.png)

and encoded in Unicode as `U+041D 0438 043A 043E 043B 0430 0439`.

å¹¶ä¸”åœ¨ Unicode ä¸­ç¼–ç ä¸º `U+041D 0438 043A 043E 043B 0430 0439`ã€‚

The Bulgarian name Nikolay is written:

ä¿åŠ åˆ©äºšè¯­åå­— Nikolay çš„å†™æ³•å¦‚ä¸‹ï¼š

![](https://tonsky.me/blog/unicode/nikolay_bg.png)

and encoded in Unicode as `U+041D 0438 043A 043E 043B 0430 0439`. Exactly the same!

å¹¶ä¸”åœ¨ Unicode ä¸­ç¼–ç ä¸º `U+041D 0438 043A 043E 043B 0430 0439`ã€‚å®Œå…¨ä¸€æ ·ï¼

Wait a second! How does the computer know when to render Bulgarian-style glyphs and when to use Russian ones?

ç­‰ä¸€ä¸‹ï¼è®¡ç®—æœºå¦‚ä½•çŸ¥é“ä½•æ—¶å‘ˆç°ä¿åŠ åˆ©äºšå¼å­—å½¢ï¼Œä½•æ—¶ä½¿ç”¨ä¿„è¯­å­—å½¢ï¼Ÿ

Short answer: it doesnâ€™t. Unfortunately, Unicode is not a perfect system, and it has many shortcomings. Among them is assigning the same code point to glyphs that are supposed to look differently, like Cyrillic Lowercase K and Bulgarian Lowercase K (both are `U+043A`).

ç®€çŸ­çš„å›ç­”ï¼šå®ƒä¸çŸ¥é“ã€‚ä¸å¹¸çš„æ˜¯ï¼ŒUnicode ä¸æ˜¯ä¸€ä¸ªå®Œç¾çš„ç³»ç»Ÿï¼Œå®ƒæœ‰å¾ˆå¤šç¼ºç‚¹ã€‚å…¶ä¸­ä¹‹ä¸€å°±æ˜¯æ˜¯å°†ç›¸åŒçš„ç ä½åˆ†é…ç»™åº”è¯¥çœ‹èµ·æ¥ä¸åŒçš„å­—å½¢ï¼Œæ¯”å¦‚è¥¿é‡Œå°”å°å†™å­—æ¯ <span lang="ru">K</span> å’Œä¿åŠ åˆ©äºšè¯­å°å†™å­—æ¯ <span lang="bg">K</span>ï¼ˆéƒ½æ˜¯ `U+043A`ï¼‰ã€‚

From what I understand, Asian people [get it much worse](https://en.wikipedia.org/wiki/Han_unification): many Chinese, Japanese, and Korean logograms that are written very differently get assigned the same code point:

æ®æˆ‘æ‰€çŸ¥ï¼Œäºšæ´²äºº[é­å—çš„æ‰“å‡»æ›´å¤§](https://en.wikipedia.org/wiki/Han_unification)ï¼šè®¸å¤šä¸­æ–‡ã€æ—¥æ–‡å’ŒéŸ©æ–‡çš„è±¡å½¢æ–‡å­—è¢«åˆ†é…äº†ç›¸åŒçš„ç ä½ï¼š

![ä¸åŒåŒºåŸŸè®¾ç½®ä¸‹çš„ `U+8FD4`](https://upload.wikimedia.org/wikipedia/commons/2/23/Source_Han_Sans_Version_Difference.svg)

Unicode motivation is to save code points space (my guess). Information on how to render is supposed to be transferred outside of the string, as locale/language metadata.

Unicode è¿™ä¹ˆåšæ˜¯å‡ºäºèŠ‚çœç ä½ç©ºé—´çš„åŠ¨æœºï¼ˆæˆ‘çŒœçš„ï¼‰ã€‚æ¸²æŸ“ä¿¡æ¯åº”è¯¥åœ¨å­—ç¬¦ä¸²ä¹‹å¤–ä¼ é€’ï¼Œä½œä¸ºåŒºåŸŸè®¾ç½®ï¼ˆlocaleï¼‰/è¯­è¨€çš„å…ƒæ•°æ®ã€‚

Unfortunately, it fails the original goal of Unicode:

ä¸å¹¸çš„æ˜¯ï¼Œå®ƒæœªèƒ½å®ç° Unicode æœ€åˆçš„ç›®æ ‡ï¼š

> [...] no escape sequence or control code is required to specify any character in any language.

> [...] ä¸éœ€è¦è½¬ä¹‰åºåˆ—æˆ–æ§åˆ¶ç æ¥æŒ‡å®šä»»ä½•è¯­è¨€ä¸­çš„ä»»ä½•å­—ç¬¦ã€‚

In practice, dependency on locale brings a lot of problems:

åœ¨å®é™…ä¸­ï¼Œå¯¹åŒºåŸŸè®¾ç½®çš„ä¾èµ–å¸¦æ¥äº†å¾ˆå¤šé—®é¢˜ï¼š

1. Being metadata, locale often gets lost.
1. ä½œä¸ºå…ƒæ•°æ®ï¼ŒåŒºåŸŸè®¾ç½®ç»å¸¸ä¸¢å¤±ã€‚
2. People are not limited to a single locale. For example, I can read and write English (USA), English (UK), German, and Russian. Which locale should I set my computer to?
2. äººä»¬ä¸é™äºå•ä¸€çš„åŒºåŸŸè®¾ç½®ã€‚ä¾‹å¦‚ï¼Œæˆ‘å¯ä»¥é˜…è¯»å’Œå†™ä½œè‹±è¯­ï¼ˆç¾å›½ï¼‰ã€è‹±è¯­ï¼ˆè‹±å›½ï¼‰ã€å¾·è¯­å’Œä¿„è¯­ã€‚æˆ‘åº”è¯¥å°†æˆ‘çš„è®¡ç®—æœºè®¾ç½®ä¸ºå“ªä¸ªåŒºåŸŸï¼Ÿ
3. Itâ€™s hard to mix and match. Like Russian names in Bulgarian text or vice versa. Why not? Itâ€™s the internet, people from all cultures hang out here.
3. æ··èµ·æ¥åå†åŒ¹é…å¾ˆéš¾ã€‚æ¯”å¦‚ä¿åŠ åˆ©äºšæ–‡ä¸­çš„ä¿„è¯­åå­—ï¼Œåä¹‹äº¦ç„¶ã€‚ä¸ºä»€ä¹ˆä¸å‘¢ï¼Ÿè¿™æ˜¯äº’è”ç½‘ï¼Œæ¥è‡ªå„ç§æ–‡åŒ–çš„äººéƒ½åœ¨è¿™é‡Œå†²æµªã€‚
4. Thereâ€™s no place to specify the locale. Even making the two screenshots above was non-trivial because in most software, thereâ€™s no dropdown or text input to change locale.
4. æ²¡æœ‰åœ°æ–¹æŒ‡å®šåŒºåŸŸè®¾ç½®ã€‚å³ä½¿æ˜¯åˆ¶ä½œä¸Šé¢çš„ä¸¤ä¸ªæˆªå›¾ä¹Ÿæ˜¯æ¯”è¾ƒå¤æ‚çš„ï¼Œå› ä¸ºåœ¨å¤§å¤šæ•°è½¯ä»¶ä¸­ï¼Œæ²¡æœ‰ä¸‹æ‹‰èœå•æˆ–æ–‡æœ¬è¾“å…¥æ¥æ›´æ”¹åŒºåŸŸè®¾ç½®ã€‚
5. When needed, it had to be guessed. For example, Twitter tries to guess the locale from the text of the tweet itself (because where else could it get it from?) and sometimes gets it wrong:
5. åœ¨éœ€è¦çš„æ—¶å€™ï¼Œæˆ‘ä»¬åªèƒ½é çŒœã€‚ä¾‹å¦‚ï¼ŒTwitter è¯•å›¾ä»æ¨æ–‡æœ¬èº«çš„æ–‡æœ¬ä¸­çŒœæµ‹åŒºåŸŸè®¾ç½®ï¼ˆå› ä¸ºå®ƒè¿˜èƒ½ä»å“ªé‡Œå¾—åˆ°å‘¢ï¼Ÿï¼‰æ—¶æœ‰æ—¶ä¼šçŒœé”™[^twitter]ï¼š

[^twitter]: Twitter é”™è¯¯æ¸²æŸ“ä¿„è¯­ä¸ºä¿åŠ åˆ©äºšè¯­â€”â€”æ³¨æ„ <span lang='bg'>Ğ¸</span>ã€<span lang='ru'>Ğ¹</span>ã€<span lang='bg'>ÑŒ</span>ã€<span lang='bg'>Ğº</span>ã€<span lang='bg'>Ğ·</span> ç­‰å­—æ¯çš„å­—å½¢ã€‚

<a href="https://twitter.com/nikitonsky/status/1171115067112398849">
  <Img src="https://tonsky.me/blog/unicode/twitter_locale.jpg" />
</a>

![](/tonsky/tweet-translated.webp)

## Why does `String::toLowerCase()` accepts Locale as an argument?

## ä¸ºä»€ä¹ˆ `String::toLowerCase()` çš„å‚æ•°ä¸­æœ‰ä¸ªåŒºåŸŸè®¾ç½®ï¼Ÿ

Another unfortunate example of locale dependence is the Unicode handling of dotless `i` in the Turkish language.

Unicode å¤„ç†åœŸè€³å…¶è¯­ä¸­æ— ç‚¹ `i` çš„æ–¹å¼æ˜¯è¯´æ˜å…¶å¯¹åŒºåŸŸè®¾ç½®ä¾èµ–çš„å¦ä¸€ä¸ªä¾‹å­ã€‚

Unlike English, Turks have two `I` variants: dotted and dotless. Unicode decided to reuse `I` and `i` from ASCII and only add two new code points: `Ä°` and `Ä±`.

ä¸åŒäºè‹±å›½äººï¼ŒåœŸè€³å…¶äººæœ‰ä¸¤ç§ `I` å˜ä½“ï¼šæœ‰ç‚¹çš„å’Œæ— ç‚¹çš„ã€‚Unicode å†³å®šé‡ç”¨ ASCII ä¸­çš„ `I` å’Œ `i`ï¼Œå¹¶åªæ·»åŠ ä¸¤ä¸ªæ–°çš„ç ä½ï¼š`Ä°` å’Œ `Ä±`ã€‚

Unfortunately, that made `toLowerCase`/`toUpperCase` behave differently on the same input:

ä¸å¹¸çš„æ˜¯ï¼Œè¿™ä½¿å¾— `toLowerCase`/`toUpperCase` åœ¨ç›¸åŒçš„è¾“å…¥ä¸Šè¡¨ç°ä¸åŒï¼š

<Code lang='js' code={`var en_US = Locale.of("en", "US");
var tr = Locale.of("tr");

"I".toLowerCase(en_US); // => "i"
"I".toLowerCase(tr); // => "Ä±"

"i".toUpperCase(en_US); // => "I"
"i".toUpperCase(tr); // => "Ä°"'`} />

So no, you canâ€™t convert string to lowercase without knowing what language that string is written in.

æ‰€ä»¥ï¼Œä¸ï¼Œä½ ä¸èƒ½åœ¨ä¸çŸ¥é“å­—ç¬¦ä¸²æ˜¯ç”¨ä»€ä¹ˆè¯­è¨€ç¼–å†™çš„æƒ…å†µä¸‹å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºå°å†™ã€‚

## I live in the US/UK, should I even care?

## æˆ‘ä½åœ¨ç¾å›½/è‹±å›½ï¼Œæˆ‘åº”è¯¥å…³å¿ƒå—ï¼Ÿ

<img
  src="https://tonsky.me/blog/unicode/english@2x.png"
  style="aspect-ratio: 600/67; "
  width="600"
  height="67"
  alt={`Still â€” yes. Even pure English text uses lots of â€œtypographical signsâ€ that aren't available in ASCII, like:`}
/>

ä»ç„¶æ˜¯çš„ã€‚å³ä½¿æ˜¯çº¯è‹±æ–‡æ–‡æœ¬ä¹Ÿä½¿ç”¨äº†è®¸å¤š ASCII ä¸­æ²¡æœ‰çš„ã€Œæ’ç‰ˆç¬¦å·ã€ï¼Œæ¯”å¦‚ï¼š

- quotation marks `â€œ` `â€` `â€˜` `â€™`,
- å¼•å· `â€œ` `â€` `â€˜` `â€™`ï¼Œ
- apostrophe `â€™`,
- æ’‡å· `â€™`ï¼Œ
- dashes `â€“` `â€”`,
- è¿æ¥å· `â€“` `â€”`ï¼Œ
- different variations of spaces (figure, hair, non-breaking),
- ç©ºæ ¼çš„å˜ä½“ï¼ˆé•¿ç©ºæ ¼ã€çŸ­ç©ºæ ¼ã€ä¸æ¢è¡Œç©ºæ ¼ï¼‰ï¼Œ
- bullets `â€¢` `â– ` `â˜`,
- ç‚¹ `â€¢` `â– ` `â˜`ï¼Œ
- currency symbols other than the `$` (kind of tells you who invented computers, doesnâ€™t it?): `â‚¬` `Â¢` `Â£`,
- é™¤äº† `$` ä¹‹å¤–çš„è´§å¸ç¬¦å·ï¼ˆè¿™æœ‰ç‚¹å‘Šè¯‰ä½ æ˜¯è°å‘æ˜äº†è®¡ç®—æœºï¼Œä¸æ˜¯å—ï¼Ÿï¼‰ï¼š`â‚¬` `Â¢` `Â£`ï¼Œ
- mathematical signsâ€”plus `+` and equals `=` are part of ASCII, but minus `âˆ’` and multiply `Ã—` are not <nobr>Â¯\_(ãƒ„)\_/Â¯</nobr>,
- æ•°å­¦ç¬¦å·â€”â€”åŠ å· `+` å’Œç­‰å· `=` æ˜¯ ASCII çš„ä¸€éƒ¨åˆ†ï¼Œä½†å‡å· `âˆ’` å’Œä¹˜å· `Ã—` ä¸æ˜¯ <nobr>Â¯\_(ãƒ„)\_/Â¯</nobr>ï¼Œ
- various other signs `Â©` `â„¢` `Â¶` `â€ ` `Â§`.
- å„ç§å…¶ä»–ç¬¦å· `Â©` `â„¢` `Â¶` `â€ ` `Â§`ã€‚

Hell, you canâ€™t even spell `cafÃ©`, `piÃ±ata`, or `naÃ¯ve` without Unicode. So yes, we are all in it together, even Americans.

è§é¬¼ï¼Œä½ ç”šè‡³ä¸èƒ½æ‹¼å†™ `cafÃ©`ã€`piÃ±ata` æˆ– `naÃ¯ve` è€Œä¸ä½¿ç”¨ Unicodeã€‚æ‰€ä»¥æ˜¯çš„ï¼Œæˆ‘ä»¬åœ¨ä¸€æ¡èˆ¹ä¸Šï¼Œå³ä½¿æ˜¯ç¾å›½äººã€‚

TouchÃ©.

æ³•å›½äººï¼šä½ ä¹¦çš„é˜Ÿã€‚[^touche]
[^touche]: åŸæ–‡æ˜¯æ³•è¯­<q lang="fr">TouchÃ©</q>ï¼Œæ„ä¸ºã€Œè¯´å¾—å¥½ã€ã€ã€Œä¸€é’ˆè§è¡€ã€ã€‚

## What are surrogate pairs?

## ä»€ä¹ˆæ˜¯ä»£ç†å¯¹ï¼Ÿ

That goes back to Unicode v1. The first version of Unicode was supposed to be fixed-width. A 16-bit fixed width, to be exact:

è¿™è¦è¿½æº¯åˆ° Unicode v1ã€‚Unicode çš„ç¬¬ä¸€ä¸ªç‰ˆæœ¬åº”è¯¥æ˜¯å›ºå®šå®½åº¦çš„ã€‚å‡†ç¡®åœ°è¯´ï¼Œæ˜¯ 16 ä½å›ºå®šå®½åº¦ï¼š

<Img
src="https://tonsky.me/blog/unicode/unicode1@2x.png"
zhcap="Unicode æ ‡å‡†çš„ 1.0 ç‰ˆæœ¬, 1991 å¹´ 10 æœˆ"
encap="Version 1.0 of the Unicode Standard, October 1991"
width="840"
height="558"
/>

They believed 65,536 characters would be enough for all human languages. They were almost right!

ä»–ä»¬ç›¸ä¿¡ 65,536 ä¸ªå­—ç¬¦è¶³ä»¥æ¶µç›–æ‰€æœ‰äººç±»è¯­è¨€ã€‚ä»–ä»¬å‡ ä¹æ˜¯å¯¹çš„ï¼

When they realized they needed more code points, UCS-2 (an original version of UTF-16 without surrogates) was already used in many systems. 16 bit, fixed-width, it only gives you 65,536 characters. What can you do?

å½“ä»–ä»¬æ„è¯†åˆ°ä»–ä»¬éœ€è¦æ›´å¤šçš„ç ä½æ—¶ï¼ŒUCS-2ï¼ˆæ²¡æœ‰ä»£ç†å¯¹çš„ UTF-16 çš„åŸå§‹ç‰ˆæœ¬ï¼‰å·²ç»åœ¨è®¸å¤šç³»ç»Ÿä¸­ä½¿ç”¨äº†ã€‚16 ä½ï¼Œå›ºå®šå®½åº¦ï¼Œåªç»™ä½  65,536 ä¸ªå­—ç¬¦ã€‚ä½ èƒ½åšä»€ä¹ˆå‘¢ï¼Ÿ

Unicode decided to allocate some of these 65,536 characters to encode higher code points, essentially converting fixed-width UCS-2 into variable-width UTF-16.

Unicode å†³å®šå°†è¿™ 65,536 ä¸ªå­—ç¬¦ä¸­çš„ä¸€äº›åˆ†é…ç»™ç¼–ç æ›´é«˜ç ä½çš„å­—ç¬¦ï¼Œä»è€Œå°†å›ºå®šå®½åº¦çš„ UCS-2 è½¬æ¢ä¸ºå¯å˜å®½åº¦çš„ UTF-16ã€‚

A surrogate pair is two UTF-16 units used to encode a single Unicode code point. For example, `D83D DCA9` (two 16-bit units) encodes _one_ code point, `U+1F4A9`.

<dfn>ä»£ç†å¯¹</dfn>ï¼ˆ<span>surrogate pair</span>ï¼‰æ˜¯ç”¨äºç¼–ç å•ä¸ª Unicode ç ä½çš„ä¸¤ä¸ª UTF-16 å•ä½ã€‚ä¾‹å¦‚ï¼Œ`D83D DCA9`ï¼ˆä¸¤ä¸ª 16 ä½å•ä½ï¼‰ç¼–ç äº†ä¸€ä¸ªç ä½ï¼Œ`U+1F4A9`ã€‚

The top 6 bits in surrogate pairs are used for the mask, leaving 2Ã—10 free bits to spare:

ä»£ç†å¯¹ä¸­çš„å‰ 6 ä½ç”¨äºæ©ç ï¼Œå‰©ä¸‹ 2Ã—10 ä¸ªç©ºé—²ä½ï¼š

<pre>
   High Surrogate          Low Surrogate
        D800        ++          DC00
1101 10?? ???? ???? ++ 1101 11?? ???? ????
</pre>

Technically, both halves of the surrogate pair can be seen as Unicode code points, too. In practice, the whole range from `U+D800` to `U+DFFF` is allocated as â€œfor surrogate pairs onlyâ€. Code points from there are not even considered valid in any other encodings.

ä»æŠ€æœ¯ä¸Šè®²ï¼Œä»£ç†å¯¹çš„ä¸¤åŠä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯ Unicode ç ä½ã€‚å®é™…ä¸Šï¼Œä» `U+D800` åˆ° `U+DFFF` çš„æ•´ä¸ªèŒƒå›´éƒ½è¢«åˆ†é…ä¸ºã€Œä»…ç”¨äºä»£ç†å¯¹ã€ã€‚ä»é‚£é‡Œå¼€å§‹çš„ç ä½ç”šè‡³åœ¨ä»»ä½•å…¶ä»–ç¼–ç ä¸­éƒ½ä¸è¢«è®¤ä¸ºæ˜¯æœ‰æ•ˆçš„ã€‚

<Plane
zhcap="è¿™ä¸ªåœ¨å·²ç»éå¸¸æ‹¥æŒ¤çš„åŸºæœ¬å¤šè¯­è¨€å¹³é¢ä¸Šçš„ç©ºé—´æ°¸è¿œä¸ä¼šå†è¢«æ‹¿æ¥å¹²ä»»ä½•å¥½äº‹"
encap="This space on a very crammed Basic Multilingual Plane will never be used for anything good ever again
">
  <g transform="scale(0.6) translate(391,645)" data-href="https://tonsky.me/blog/unicode/bmp@2x.png">
    <path d="M438.5 17C349.72 12.1302 215.423 7.75743 148.212 5.8528C139.796 5.61431 131.411 6.84615 123.414 9.4789L37.054 37.9102C22.9757 42.545 12.8279 54.8766 10.9895 69.5838L10.1055 76.6557C9.09987 84.701 12.101 92.7284 18.1379 98.1409V98.1409C21.3247 100.998 25.1984 102.979 29.3802 103.891L81.8143 115.324C86.9233 116.438 92.106 117 97.335 117C149.492 117 241.199 117 245 117C248.575 117 322.194 105.015 370.158 97.115C380.609 95.3934 390.536 91.4131 399.293 85.4535L448.493 51.9702C454.44 47.9225 458 41.1943 458 34V34" stroke="#FF00C9" stroke-width="11" stroke-linecap="round" fill="transparent" fill-opacity="0" />
  </g>
</Plane>

## Is UTF-16 still alive?

## UTF-16 è¿˜æ´»ç€å—ï¼Ÿ

Yes!

æ˜¯çš„ï¼

The promise of a fixed-width encoding that covers all human languages was so compelling that many systems were eager to adopt it. Among them were Microsoft Windows, Objective-C, Java, JavaScript, .NET, Python 2, QT, SMS, and CD-ROM!

ä¸€ä¸ªå®šé•¿çš„ã€æ¶µç›–æ‰€æœ‰äººç±»è¯­è¨€çš„ç¼–ç çš„è®¸è¯ºæ˜¯å¦‚æ­¤ä»¤äººä¿¡æœï¼Œä»¥è‡³äºè®¸å¤šç³»ç»Ÿéƒ½è¿«ä¸åŠå¾…åœ°é‡‡ç”¨äº†å®ƒï¼ŒåŒ…æ‹¬ Microsoft Windowsã€Objective-Cã€Javaã€JavaScriptã€.NETã€Python 2ã€QTã€SMS å’Œ CD-ROMï¼

Since then, Python has moved on, CD-ROM has become obsolete, but the rest is stuck with UTF-16 or even UCS-2. So UTF-16 lives there as in-memory representation.

è‡ªä»é‚£æ—¶ä»¥æ¥ï¼ŒPython å·²ç»è¿›æ­¥äº†ï¼ŒCD-ROM å·²ç»è¿‡æ—¶äº†ï¼Œä½†å…¶ä½™çš„ä»ç„¶åœç•™åœ¨ UTF-16 æˆ–ç”šè‡³ UCS-2ã€‚å› æ­¤ï¼ŒUTF-16 ä½œä¸ºå†…å­˜è¡¨ç¤ºè€Œå­˜åœ¨ã€‚

In practical terms today, UTF-16 has roughly the same usability as UTF-8. Itâ€™s also variable-length; counting UTF-16 units is as useless as counting bytes or code points, grapheme clusters are still a pain, etc. The only difference is memory requirements.

åœ¨ä»Šå¤©çš„å®é™…æƒ…å†µä¸‹ï¼ŒUTF-16 çš„å¯ç”¨æ€§ä¸ UTF-8 å¤§è‡´ç›¸åŒã€‚å®ƒä¹Ÿæ˜¯å˜é•¿çš„ï¼›è®¡ç®— UTF-16 å•å…ƒä¸è®¡ç®—å­—èŠ‚æˆ–ç ä½ä¸€æ ·æ²¡æœ‰ç”¨ï¼Œå­—ä½ç°‡ä»ç„¶å¾ˆç—›è‹¦ï¼Œç­‰ç­‰ã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯å†…å­˜éœ€æ±‚ã€‚

The only downside of UTF-16 is that everything else is UTF-8, so it requires conversion every time a string is read from the network or from disk.

UTF-16 çš„å”¯ä¸€ç¼ºç‚¹æ˜¯å…¶ä»–æ‰€æœ‰ä¸œè¥¿éƒ½æ˜¯ UTF-8ï¼Œå› æ­¤æ¯æ¬¡ä»ç½‘ç»œæˆ–ç£ç›˜è¯»å–å­—ç¬¦ä¸²æ—¶éƒ½è¦è½¬æ¢ä¸€ä¸‹ã€‚

Also, fun fact: the number of planes Unicode has (17) is defined by how much you can express with surrogate pairs in UTF-16.

è¿˜æœ‰ä¸€ä¸ªæœ‰è¶£çš„äº‹å®ï¼šUnicode çš„å¹³é¢æ•°ï¼ˆ17ï¼‰æ˜¯ç”± UTF-16 ä¸­ä»£ç†å¯¹å¯ä»¥è¡¨è¾¾çš„å†…å®¹å†³å®šçš„ã€‚

## Conclusion

## ç»“è®º

To sum it up:

è®©æˆ‘ä»¬æ€»ç»“ä¸€ä¸‹ï¼š

- Unicode has won.
- Unicode å·²ç»èµ¢äº†ã€‚
- UTF-8 is the most popular encoding for data in transfer and at rest.
- UTF-8 æ˜¯ä¼ è¾“å’Œå‚¨å­˜æ•°æ®æ—¶ä½¿ç”¨æœ€å¹¿æ³›çš„ç¼–ç ã€‚
- UTF-16 is still sometimes used as an in-memory representation.
- UTF-16 ä»ç„¶æœ‰æ—¶è¢«ç”¨ä½œå†…å­˜è¡¨ç¤ºã€‚
- The two most important views for strings are bytes (allocate memory/copy/encode/decode) and extended grapheme clusters (all semantic operations).
- å­—ç¬¦ä¸²çš„ä¸¤ä¸ªæœ€é‡è¦çš„è§†å›¾æ˜¯å­—èŠ‚ï¼ˆåˆ†é…å†…å­˜/å¤åˆ¶/ç¼–ç /è§£ç ï¼‰å’Œæ‰©å±•å­—ä½ç°‡ï¼ˆæ‰€æœ‰è¯­ä¹‰æ“ä½œï¼‰ã€‚
- Using code points for iterating over a string is wrong. They are not the basic unit of writing. One grapheme could consist of multiple code points.
- ä»¥ç ä½ä¸ºå•ä½æ¥è¿­ä»£å­—ç¬¦ä¸²æ˜¯é”™è¯¯çš„ã€‚å®ƒä»¬ä¸æ˜¯ä¹¦å†™çš„åŸºæœ¬å•ä½ã€‚ä¸€ä¸ªå­—ä½å¯èƒ½ç”±å¤šä¸ªç ä½ç»„æˆã€‚
- To detect grapheme boundaries, you need Unicode tables.
- è¦æ£€æµ‹å­—ä½çš„è¾¹ç•Œï¼Œä½ éœ€è¦è¡¨æ ¼ã€‚
- Use a Unicode library for everything Unicode, even boring stuff like `strlen`, `indexOf` and `substring`.
- å¯¹äºæ‰€æœ‰ Unicode ç›¸å…³çš„ä¸œè¥¿ï¼Œç”šè‡³æ˜¯åƒ `strlen`ã€`indexOf` å’Œ `substring` è¿™æ ·çš„æ— èŠçš„ä¸œè¥¿ï¼Œéƒ½è¦ä½¿ç”¨ Unicode åº“ã€‚
- Unicode updates every year, and rules sometimes change.
- Unicode æ¯å¹´æ›´æ–°ä¸€æ¬¡ï¼Œè§„åˆ™æœ‰æ—¶ä¼šæ”¹å˜ã€‚
- Unicode strings need to be normalized before they can be compared.
- Unicode å­—ç¬¦ä¸²åœ¨æ¯”è¾ƒä¹‹å‰éœ€è¦è¿›è¡Œå½’ä¸€åŒ–ã€‚
- Unicode depends on locale for some operations and for rendering.
- Unicode åœ¨æŸäº›æ“ä½œå’Œæ¸²æŸ“ä¸­ä¾èµ–äºåŒºåŸŸè®¾ç½®ã€‚
- All this is important even for pure English text.
- å³ä½¿æ˜¯çº¯è‹±æ–‡æ–‡æœ¬ï¼Œè¿™äº›éƒ½å¾ˆé‡è¦ã€‚

Overall, yes, Unicode is not perfect, but the fact that

æ€»çš„æ¥è¯´ï¼Œæ˜¯çš„ï¼ŒUnicode ä¸å®Œç¾ï¼Œä½†

1. an encoding exists that covers all possible languages at once,
1. æœ‰ä¸€ä¸ªèƒ½è¦†ç›–æ‰€æœ‰å¯èƒ½è¯­è¨€çš„ç¼–ç ã€
1. the entire world agrees to use it,
1. å…¨ä¸–ç•Œéƒ½åŒæ„ä½¿ç”¨å®ƒã€
1. we can completely forget about encodings and conversions and all that stuff
1. æˆ‘ä»¬å¯ä»¥å®Œå…¨å¿˜è®°ç¼–ç å’Œè½¬æ¢ä¹‹ç±»çš„ä¸œè¥¿

is a miracle. Send this to your fellow programmers so they can learn about it, too.

çš„äº‹å®æ˜¯ä¸€ä¸ªå¥‡è¿¹ã€‚æŠŠè¿™ç¯‡æ–‡ç« å‘é€ç»™ä½ çš„ç¨‹åºå‘˜ç¾¤å‹ä»¬ï¼Œè®©ä»–ä»¬ä¹Ÿèƒ½äº†è§£å®ƒã€‚

<Loud en="Thereâ€™s such a thing as plain text, and itâ€™s encoded with UTF-8.">çš„ç¡®æœ‰è¿™æ ·ä¸€ç§ä¸œè¥¿å«åšçº¯æ–‡æœ¬ï¼Œ<br />å¹¶ä¸”å®ƒä½¿ç”¨ UTF-8 è¿›è¡Œç¼–ç ã€‚</Loud>

Thanks Lev Walkin and my patrons for reading early drafts of this article.

æ„Ÿè°¢ Lev Walkin å’Œæˆ‘çš„èµåŠ©è€…ä»¬é˜…è¯»äº†æœ¬æ–‡çš„æ—©æœŸè‰ç¨¿ã€‚

<div class="footer">
  2023 å¹´ 10 æœˆ 2 æ—¥ Â· åœ¨
  [HackerNews](https://news.ycombinator.com/item?id=37735801) ä¸Šè®¨è®º Â·
  ç¿»è¯‘äº 2023 å¹´ 10 æœˆ 27 æ—¥
</div>

<br />
<br />

### Translator's note

### è¯‘è€…æ³¨
